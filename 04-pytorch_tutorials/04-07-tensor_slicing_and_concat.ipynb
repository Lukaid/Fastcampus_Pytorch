{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Tensor Slicing and Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing and Concatenation\n",
    "\n",
    "- 자르고 붙이기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing and Slicing\n",
    "\n",
    "Prepare target tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor([[[1, 2],\n",
    "                        [3, 4]],\n",
    "                       [[5, 6],\n",
    "                        [7, 8]],\n",
    "                       [[9, 10],\n",
    "                        [11, 12]]])\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access to certain dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[1., 2.],\n        [3., 4.]])\ntensor([[1., 2.],\n        [3., 4.]])\ntensor([1., 2.])\ntensor([2., 4.])\ntensor([3., 4.])\n"
     ]
    }
   ],
   "source": [
    "print(x[0])\n",
    "print(x[0, :])\n",
    "print(x[0, 0, :])\n",
    "print(x[0, :, 1]) # 얘는 다른 디멘젼에 있는 애들도 가져옴\n",
    "print(x[0][:][1]) # 다름 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[ 9., 10.],\n        [11., 12.]])\ntensor([[ 9., 10.],\n        [11., 12.]])\ntensor([[ 9., 10.],\n        [11., 12.]])\n"
     ]
    }
   ],
   "source": [
    "print(x[-1])\n",
    "print(x[-1, :])\n",
    "print(x[-1, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[ 1.,  2.],\n        [ 5.,  6.],\n        [ 9., 10.]])\n"
     ]
    }
   ],
   "source": [
    "print(x[:, 0, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access by range. Note that the number of dimensions would not be changed.\n",
    "\n",
    "레인지로 그니까 범위로 짜르면 디멘젼이 1이라도 없어지지 않는다\n",
    "\n",
    "그냥 짜르면 디멘젼 리덕션이 일어남"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([2, 2, 2])\n",
      "torch.Size([3, 1, 2])\n",
      "torch.Size([3, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "print(x[1:3, :, :].size())\n",
    "print(x[:, :1, :].size())\n",
    "print(x[:, :-1, :].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split: Split tensor to desirable shapes.\n",
    "- 텐서 자체를 여러개로 쪼갬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([10, 4])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor(10, 4)\n",
    "x\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(tensor([[4.2488e-05, 6.7137e-07, 6.8993e-07, 2.1627e+23],\n        [1.0664e-08, 1.1039e-05, 3.1369e+27, 7.0800e+31],\n        [3.1095e-18, 7.7052e+31, 1.9447e+31, 2.0558e+32],\n        [1.8755e+28, 3.1093e-18, 1.9421e+31, 2.7491e+20]]), tensor([[2.3078e-12, 1.8179e+31, 1.8524e+28, 9.6695e-06],\n        [1.0779e-08, 1.0186e-11, 1.3168e-08, 4.2488e-05],\n        [6.7137e-07, 6.8993e-07, 2.1627e+23, 1.0664e-08],\n        [1.1966e+22, 3.1097e-18, 6.4805e-10, 6.3007e-10]]), tensor([[4.2481e-05, 7.0264e-04, 2.7094e-09, 6.8240e-07],\n        [2.6371e-09, 2.3329e-18, 1.9205e+31, 3.2314e-18]]))\n<class 'tuple'>\ntorch.Size([4, 4])\ntorch.Size([4, 4])\ntorch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "splits = x.split(4, dim=0) # 0번 디멘젼이 4개가 되도록 잘라줘\n",
    "print(splits)\n",
    "print(type(splits)) # tuple에 담겨서 리턴\n",
    "\n",
    "for s in splits:\n",
    "    print(s.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chunk: Split tensor to number of chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.FloatTensor(14, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([5, 4])\ntorch.Size([5, 4])\ntorch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "chunks = x.chunk(3, dim=0) #얘는 0번 디멘젼이 텐서를 3개로 잘라줘\n",
    "\n",
    "for c in chunks:\n",
    "    print(c.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### index_select: Select elements by using dimension index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([3, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor([[[1, 1],\n",
    "                        [2, 2]],\n",
    "                       [[3, 3],\n",
    "                        [4, 4]],\n",
    "                       [[5, 5],\n",
    "                        [6, 6]]])\n",
    "indice = torch.LongTensor([2, 1])\n",
    "\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[[5., 5.],\n         [6., 6.]],\n\n        [[3., 3.],\n         [4., 4.]]])\ntorch.Size([2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "y = x.index_select(dim=0, index=indice) # 인덱스는 꼭 텐서가 들어가야하나?\n",
    "\n",
    "print(y)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cat: Concatenation of multiple tensors in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.FloatTensor([[1, 2, 3],\n",
    "                       [4, 5, 6],\n",
    "                       [7, 8, 9]])\n",
    "y = torch.FloatTensor([[10, 11, 12],\n",
    "                       [13, 14, 15],\n",
    "                       [16, 17, 18]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[ 1.,  2.,  3.],\n        [ 4.,  5.,  6.],\n        [ 7.,  8.,  9.],\n        [10., 11., 12.],\n        [13., 14., 15.],\n        [16., 17., 18.]])\ntorch.Size([6, 3])\n"
     ]
    }
   ],
   "source": [
    "z = torch.cat([x, y], dim=0) # 0번디멘젼으로 붙여줘, 0번 디멘젼 사이즈를 더해줘\n",
    "print(z)\n",
    "print(z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[ 1.,  2.,  3., 10., 11., 12.],\n        [ 4.,  5.,  6., 13., 14., 15.],\n        [ 7.,  8.,  9., 16., 17., 18.]])\ntorch.Size([3, 6])\n"
     ]
    }
   ],
   "source": [
    "z = torch.cat([x, y], dim=-1) # 맨 뒤 디멘젼으로 붙여줘\n",
    "print(z)\n",
    "print(z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stack: Stacking of multiple tensors in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[[ 1.,  2.,  3.],\n         [ 4.,  5.,  6.],\n         [ 7.,  8.,  9.]],\n\n        [[10., 11., 12.],\n         [13., 14., 15.],\n         [16., 17., 18.]]])\ntorch.Size([2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "z = torch.stack([x, y]) # 차원이 하나 더 생김\n",
    "print(z)\n",
    "print(z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or you can specify the dimension. Default is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[[ 1., 10.],\n         [ 2., 11.],\n         [ 3., 12.]],\n\n        [[ 4., 13.],\n         [ 5., 14.],\n         [ 6., 15.]],\n\n        [[ 7., 16.],\n         [ 8., 17.],\n         [ 9., 18.]]])\ntorch.Size([3, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "z = torch.stack([x, y], dim=-1) #얘는 맨 뒤에 차원이 하나 더 생기는거\n",
    "print(z)\n",
    "print(z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement 'stack' function by using 'cat'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[[ 1.,  2.,  3.],\n         [ 4.,  5.,  6.],\n         [ 7.,  8.,  9.]],\n\n        [[10., 11., 12.],\n         [13., 14., 15.],\n         [16., 17., 18.]]])\ntorch.Size([2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# z = torch.stack([x, y])\n",
    "z = torch.cat([x.unsqueeze(0), y.unsqueeze(0)], dim=0)\n",
    "print(z)\n",
    "print(z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful Trick: Merge results from iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([5, 2, 2])"
      ]
     },
     "metadata": {},
     "execution_count": 82
    }
   ],
   "source": [
    "result = []\n",
    "for i in range(5):\n",
    "    x = torch.FloatTensor(2, 2)\n",
    "    result += [x] # 2 x 2가 다섯개 들어감\n",
    "\n",
    "result = torch.stack(result) #그걸 쌓으니까 5 x 2 x 2\n",
    "result.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}